{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a session with retry logic\n",
    "def create_retry_session(retries=5, backoff_factor=0.3, status_forcelist=(500, 502, 504)):\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "# Download with aria2 (parallel download)\n",
    "def download_with_aria2(url, folder):\n",
    "    file_name = os.path.basename(urlparse(url).path)\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    command = ['aria2c', '-x', '16', '-s', '16', '-c', '-o', file_name, '-d', folder, url]\n",
    "    result = subprocess.run(command)\n",
    "    return file_name if result.returncode == 0 else None\n",
    "\n",
    "# Download with requests (fallback)\n",
    "def download_file(url, folder, chunk_size=1024):\n",
    "    file_name = os.path.basename(urlparse(url).path)\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    session = create_retry_session()\n",
    "    response = session.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(file_path, 'wb') as file, tqdm(\n",
    "        desc=file_name,\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "        miniters=1\n",
    "    ) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            file.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "    return file_name\n",
    "\n",
    "# Function to handle the download process from the CSV\n",
    "def process_downloads(csv_file, download_folder):\n",
    "    # Read the CSV and add 'Status' if it doesn't exist\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if 'Status' not in df.columns:\n",
    "        df['Status'] = 'Incomplete'\n",
    "\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "    # Loop through the CSV and download files\n",
    "    for index, row in df.iterrows():\n",
    "        if df.loc[index, 'Status'] == 'Completed':\n",
    "            #print (f\"Skip . Completed\")\n",
    "            continue\n",
    "\n",
    "        download_link = row['Download Link']\n",
    "        package = row['Package']\n",
    "        print(f\"Downloading {package}...\")\n",
    "\n",
    "        try:\n",
    "            # Download via aria2 or fallback to requests\n",
    "            file_name = download_with_aria2(download_link, download_folder)\n",
    "            if not file_name:\n",
    "                file_name = download_file(download_link, download_folder)\n",
    "            \n",
    "            if file_name:\n",
    "                df.loc[index, 'Status'] = 'Completed'\n",
    "                df.loc[index, 'Downloaded File Name'] = file_name\n",
    "                print(f\"{file_name} downloaded successfully.\")\n",
    "            else:\n",
    "                df.loc[index, 'Status'] = 'Incomplete'\n",
    "                print(f\"Download failed for {package}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {package}: {e}\")\n",
    "            df.loc[index, 'Status'] = 'Error'\n",
    "\n",
    "        # Update the original CSV after each download\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    print(\"Download process completed. All updates saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading OttawaRiver-DTM-J...\n",
      "\n",
      "09/26 04:56:33 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
      "\n",
      "09/26 04:56:33 [\u001b[1;32mNOTICE\u001b[0m] Allocating disk space. Use --file-allocation=none to disable it. See --file-allocation option in man page for more details.\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 54MiB/2.8GiB(1%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 128MiB/2.8GiB(4%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 152MiB/2.8GiB(5%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 167MiB/2.8GiB(5%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 183MiB/2.8GiB(6%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 235MiB/2.8GiB(8%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 292MiB/2.8GiB(10%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 306MiB/2.8GiB(10%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 331MiB/2.8GiB(11%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 358MiB/2.8GiB(12%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 407MiB/2.8GiB(13%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 415MiB/2.8GiB(14%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 466MiB/2.8GiB(16%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 515MiB/2.8GiB(17%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 530MiB/2.8GiB(18%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 541MiB/2.8GiB(18%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 605MiB/2.8GiB(20%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 693MiB/2.8GiB(23%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 730MiB/2.8GiB(25%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 784MiB/2.8GiB(26%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 804MiB/2.8GiB(27%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 817MiB/2.8GiB(28%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 825MiB/2.8GiB(28%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 830MiB/2.8GiB(28%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 838MiB/2.8GiB(28%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 847MiB/2.8GiB(29%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 859MiB/2.8GiB(29%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 866MiB/2.8GiB(29%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 0.9GiB/2.8GiB(31%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 0.9GiB/2.8GiB(32%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 0.9GiB/2.8GiB(32%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 0.9GiB/2.8GiB(32%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 0.9GiB/2.8GiB(33%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 0.9GiB/2.8GiB(34%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 0.9GiB/2.8GiB(35%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(35%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(35%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(36%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(36%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(37%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(37%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(37%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.0GiB/2.8GiB(38%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(38%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(39%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(39%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(40%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(40%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(40%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(41%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.1GiB/2.8GiB(41%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.2GiB/2.8GiB(42%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.2GiB/2.8GiB(42%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.2GiB/2.8GiB(43%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.2GiB/2.8GiB(43%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.2GiB/2.8GiB(44%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.2GiB/2.8GiB(45%)]\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B] [FileAlloc:#26be44 1.3GiB/2.8GiB(47%)]\n",
      " *** Download Progress Summary as of Thu Sep 26 04:57:34 2024 *** \n",
      "===============================================================================\n",
      "[#26be44 0B/2.8GiB(0%) CN:1 DL:0B]\n",
      "FILE: /Volumes/Seagate Bac/DTM_ZIP/OttawaRiver-DTM-J.zip\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage example:\n",
    "csv_file = 'DTM_download_V2.csv'\n",
    "download_folder = '/Volumes/Seagate Bac/DTM_ZIP'\n",
    "process_downloads(csv_file, download_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a session with retry logic\n",
    "def create_retry_session(retries=5, backoff_factor=0.3, status_forcelist=(500, 502, 504)):\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "# Function to download a file with aria2 (parallel download)\n",
    "def download_with_aria2(url, folder):\n",
    "    file_name = os.path.basename(urlparse(url).path)\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    # Use aria2c for parallel download with retries\n",
    "    command = ['aria2c', '-x', '16', '-s', '16', '-c', '-o', file_name, '-d', folder, url]\n",
    "    result = subprocess.run(command)\n",
    "    if result.returncode == 0:\n",
    "        return file_name\n",
    "    return None\n",
    "\n",
    "# Function to download a file using requests (with retry logic)\n",
    "def download_file(url, folder, chunk_size=1024):\n",
    "    file_name = os.path.basename(urlparse(url).path)\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    \n",
    "    session = create_retry_session()\n",
    "    response = session.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    # Download with a progress bar\n",
    "    with open(file_path, 'wb') as file, tqdm(\n",
    "        desc=file_name,\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "        miniters=1\n",
    "    ) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "    return file_name\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('DTM_download.csv')\n",
    "\n",
    "# Add a new 'Status' column to track the download progress if it doesn't already exist\n",
    "if 'Status' not in df.columns:\n",
    "    df['Status'] = 'Incomplete'\n",
    "\n",
    "# Set the download folder (customize as needed)\n",
    "download_folder = '/Users/shuyang/Data/DTM_ZIP'\n",
    "\n",
    "# Create the download folder if it doesn't exist\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder)\n",
    "\n",
    "# Loop through each row in the CSV and download the file\n",
    "for index, row in df.iterrows():\n",
    "    project = row['Project']\n",
    "    package = row['Package']\n",
    "    size = float(row['Size'])  # Ensure size is treated as a float (representing GB)\n",
    "    resolution = row['Res. (m)']\n",
    "    download_link = row['Download Link']\n",
    "    \n",
    "    # Check if the file is already marked as 'Completed'\n",
    "    if df.loc[index, 'Status'] == 'Completed':\n",
    "        print(f\"{download_link} is already downloaded.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Download the file using aria2 (for robust parallel download) or fallback to requests\n",
    "        print(f\"Downloading {package} from {project} ({size} GB)...\")\n",
    "        file_name = download_with_aria2(download_link, download_folder)\n",
    "        \n",
    "        # If aria2 fails, try with requests\n",
    "        if not file_name:\n",
    "            print(f\"Aria2 download failed for {package}, retrying with requests.\")\n",
    "            file_name = download_file(download_link, download_folder)\n",
    "        \n",
    "        # Mark as completed if the file was successfully downloaded\n",
    "        if file_name:\n",
    "            df.loc[index, 'Status'] = 'Completed'\n",
    "            df.loc[index, 'Downloaded File Name'] = file_name\n",
    "            print(f\"{file_name} downloaded successfully.\")\n",
    "        else:\n",
    "            df.loc[index, 'Status'] = 'Incomplete'\n",
    "            print(f\"Download of {package} failed or incomplete.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {download_link}: {e}\")\n",
    "        df.loc[index, 'Status'] = 'Error'\n",
    "\n",
    "    # Update the CSV after each file\n",
    "    df.to_csv('DTM_download_updated.csv', index=False)\n",
    "    print(f\"CSV updated after processing {package}.\")\n",
    "\n",
    "print(\"Download process completed. All updates saved in 'DTM_download_updated.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
